{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstępny trening sieci do rozpoznawania znaków w captchy\n",
    "\n",
    "Co będziemy tutaj robić:\n",
    "\n",
    "- Zaimportujemy biblioteki\n",
    "- Wczytamy dane\n",
    "- Sprawdzimy czy dane wczytały się poprawnie\n",
    "- Zbudujemy model\n",
    "- Skompilujemy model\n",
    "- Przeuczymy sieć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "import keras.metrics\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = []\n",
    "    chars = ''.join(sorted(string.ascii_letters + string.digits)) \n",
    "    for c in chars:\n",
    "        for i in range(250):\n",
    "            if c not in string.ascii_lowercase:\n",
    "                image = load_img(path + c + str(i) + \".jpg\")\n",
    "            else:\n",
    "                image = load_img(path + 'z' + c + str(i) + \".jpg\")\n",
    "            arr = img_to_array(image)\n",
    "            data.append(arr)\n",
    "    labels = pd.read_csv(path + \"labels.csv\")\n",
    "    return np.true_divide(np.array(data), 255), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  0  1  2  3  4  5  6  7  8  ...  q  r  s  t  u  v  w  x  y  z\n",
      "0           0  1  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
      "1           1  1  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
      "2           2  1  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
      "3           3  1  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
      "4           4  1  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15500, 60, 60, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = load_data(\"../data/chars/\")\n",
    "print(labels.head())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutaj trochę ustawień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 60, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE = data[1,:,:,:].shape\n",
    "CLASS_NUM = len(''.join(sorted(string.ascii_letters + string.digits)) )\n",
    "print(CLASS_NUM)\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wymieszanie przykładów w zbiorze trenującym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z    1\n",
      "Name: 15369, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm = np.random.permutation(CLASS_NUM*250)\n",
    "ts = data[perm,:,:,:]\n",
    "y = labels.iloc[perm]\n",
    "print(y.iloc[0].loc[y.iloc[0]==1])\n",
    "plt.imshow(array_to_img(ts[0,:,:,:]))\n",
    "y = y.values[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, z którego będziemy korzystać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\daniel\\documents\\wdi19\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1\n",
    "model.add(Conv2D(16, (3,3), strides=(1,1), padding='same', use_bias=False, input_shape=INPUT_SHAPE))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2\n",
    "model.add(Conv2D(32, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "# 4\n",
    "model.add(Conv2D(128, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same'))\n",
    "\n",
    "# 5\n",
    "model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# 6\n",
    "model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# 7\n",
    "model.add(Conv2D(CLASS_NUM, (8, 8), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Reshape((CLASS_NUM,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, decay=0.0005, momentum=0.9)\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "adamax = keras.optimizers.Adamax(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=adamax, metrics=[\"accuracy\"])\n",
    "\n",
    "filepath=\"../checkpoints/pretrain-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bardzo bardzo bardzo przetrenowany model, nie róbcie tego w domu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\daniel\\documents\\wdi19\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\users\\daniel\\documents\\wdi19\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/160\n",
      "12400/12400 [==============================] - 127s 10ms/step - loss: 4.1312 - acc: 0.0161 - val_loss: 4.1276 - val_acc: 0.0119\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01194, saving model to ../checkpoints/pretrain-improvement-01-0.01.hdf5\n",
      "Epoch 2/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 4.1265 - acc: 0.0175 - val_loss: 4.1260 - val_acc: 0.0223\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.01194 to 0.02226, saving model to ../checkpoints/pretrain-improvement-02-0.02.hdf5\n",
      "Epoch 3/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 4.0566 - acc: 0.0312 - val_loss: 3.8365 - val_acc: 0.0735\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.02226 to 0.07355, saving model to ../checkpoints/pretrain-improvement-03-0.07.hdf5\n",
      "Epoch 4/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 3.2335 - acc: 0.1751 - val_loss: 2.6665 - val_acc: 0.2765\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.07355 to 0.27645, saving model to ../checkpoints/pretrain-improvement-04-0.28.hdf5\n",
      "Epoch 5/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 2.1718 - acc: 0.3810 - val_loss: 1.8919 - val_acc: 0.4329\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.27645 to 0.43290, saving model to ../checkpoints/pretrain-improvement-05-0.43.hdf5\n",
      "Epoch 6/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 1.6280 - acc: 0.5049 - val_loss: 1.4838 - val_acc: 0.5335\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.43290 to 0.53355, saving model to ../checkpoints/pretrain-improvement-06-0.53.hdf5\n",
      "Epoch 7/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 1.3834 - acc: 0.5668 - val_loss: 1.2872 - val_acc: 0.5916\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.53355 to 0.59161, saving model to ../checkpoints/pretrain-improvement-07-0.59.hdf5\n",
      "Epoch 8/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 1.1984 - acc: 0.6119 - val_loss: 1.1828 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.59161 to 0.61000, saving model to ../checkpoints/pretrain-improvement-08-0.61.hdf5\n",
      "Epoch 9/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 1.0930 - acc: 0.6430 - val_loss: 1.0901 - val_acc: 0.6445\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.61000 to 0.64452, saving model to ../checkpoints/pretrain-improvement-09-0.64.hdf5\n",
      "Epoch 10/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 1.0082 - acc: 0.6691 - val_loss: 1.0522 - val_acc: 0.6532\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.64452 to 0.65323, saving model to ../checkpoints/pretrain-improvement-10-0.65.hdf5\n",
      "Epoch 11/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.9332 - acc: 0.6891 - val_loss: 1.0046 - val_acc: 0.6642\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.65323 to 0.66419, saving model to ../checkpoints/pretrain-improvement-11-0.66.hdf5\n",
      "Epoch 12/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.8665 - acc: 0.7145 - val_loss: 1.0682 - val_acc: 0.6503\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.66419\n",
      "Epoch 13/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.8010 - acc: 0.7318 - val_loss: 0.8454 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.66419 to 0.71387, saving model to ../checkpoints/pretrain-improvement-13-0.71.hdf5\n",
      "Epoch 14/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.7747 - acc: 0.7360 - val_loss: 0.8150 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.71387\n",
      "Epoch 15/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.7251 - acc: 0.7566 - val_loss: 0.7811 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.71387 to 0.72806, saving model to ../checkpoints/pretrain-improvement-15-0.73.hdf5\n",
      "Epoch 16/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.6906 - acc: 0.7624 - val_loss: 0.8052 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.72806 to 0.72839, saving model to ../checkpoints/pretrain-improvement-16-0.73.hdf5\n",
      "Epoch 17/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.6500 - acc: 0.7773 - val_loss: 0.7165 - val_acc: 0.7448\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.72839 to 0.74484, saving model to ../checkpoints/pretrain-improvement-17-0.74.hdf5\n",
      "Epoch 18/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.6281 - acc: 0.7836 - val_loss: 0.8889 - val_acc: 0.7084\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.74484\n",
      "Epoch 19/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.5913 - acc: 0.7962 - val_loss: 0.6824 - val_acc: 0.7532\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.74484 to 0.75323, saving model to ../checkpoints/pretrain-improvement-19-0.75.hdf5\n",
      "Epoch 20/160\n",
      "12400/12400 [==============================] - 77s 6ms/step - loss: 0.5622 - acc: 0.8091 - val_loss: 0.6894 - val_acc: 0.7616\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.75323 to 0.76161, saving model to ../checkpoints/pretrain-improvement-20-0.76.hdf5\n",
      "Epoch 21/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.5482 - acc: 0.8101 - val_loss: 0.6643 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.76161 to 0.76806, saving model to ../checkpoints/pretrain-improvement-21-0.77.hdf5\n",
      "Epoch 22/160\n",
      "12400/12400 [==============================] - 135s 11ms/step - loss: 0.5311 - acc: 0.8108 - val_loss: 0.6311 - val_acc: 0.7703\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.76806 to 0.77032, saving model to ../checkpoints/pretrain-improvement-22-0.77.hdf5\n",
      "Epoch 23/160\n",
      "12400/12400 [==============================] - 135s 11ms/step - loss: 0.5077 - acc: 0.8249 - val_loss: 0.6297 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.77032 to 0.77871, saving model to ../checkpoints/pretrain-improvement-23-0.78.hdf5\n",
      "Epoch 24/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.4965 - acc: 0.8272 - val_loss: 0.6074 - val_acc: 0.7845\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.77871 to 0.78452, saving model to ../checkpoints/pretrain-improvement-24-0.78.hdf5\n",
      "Epoch 25/160\n",
      "12400/12400 [==============================] - 135s 11ms/step - loss: 0.4691 - acc: 0.8367 - val_loss: 0.5805 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.78452 to 0.79258, saving model to ../checkpoints/pretrain-improvement-25-0.79.hdf5\n",
      "Epoch 26/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.4579 - acc: 0.8394 - val_loss: 0.5945 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.79258 to 0.79419, saving model to ../checkpoints/pretrain-improvement-26-0.79.hdf5\n",
      "Epoch 27/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.4467 - acc: 0.8447 - val_loss: 0.5722 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.79419 to 0.79935, saving model to ../checkpoints/pretrain-improvement-27-0.80.hdf5\n",
      "Epoch 28/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.4262 - acc: 0.8506 - val_loss: 0.6112 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.79935\n",
      "Epoch 29/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.4203 - acc: 0.8544 - val_loss: 0.5537 - val_acc: 0.8048\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.79935 to 0.80484, saving model to ../checkpoints/pretrain-improvement-29-0.80.hdf5\n",
      "Epoch 30/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.4090 - acc: 0.8560 - val_loss: 0.5470 - val_acc: 0.8087\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.80484 to 0.80871, saving model to ../checkpoints/pretrain-improvement-30-0.81.hdf5\n",
      "Epoch 31/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3956 - acc: 0.8638 - val_loss: 0.5410 - val_acc: 0.8135\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.80871 to 0.81355, saving model to ../checkpoints/pretrain-improvement-31-0.81.hdf5\n",
      "Epoch 32/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3839 - acc: 0.8668 - val_loss: 0.5849 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.81355\n",
      "Epoch 33/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.3810 - acc: 0.8656 - val_loss: 0.5289 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.81355\n",
      "Epoch 34/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.3675 - acc: 0.8734 - val_loss: 0.5449 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.81355\n",
      "Epoch 35/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3603 - acc: 0.8735 - val_loss: 0.5411 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.81355\n",
      "Epoch 36/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.3538 - acc: 0.8756 - val_loss: 0.5270 - val_acc: 0.8187\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.81355 to 0.81871, saving model to ../checkpoints/pretrain-improvement-36-0.82.hdf5\n",
      "Epoch 37/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.3479 - acc: 0.8801 - val_loss: 0.5106 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.81871 to 0.82161, saving model to ../checkpoints/pretrain-improvement-37-0.82.hdf5\n",
      "Epoch 38/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3323 - acc: 0.8851 - val_loss: 0.5229 - val_acc: 0.8161\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.82161\n",
      "Epoch 39/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.3336 - acc: 0.8836 - val_loss: 0.4994 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.82161 to 0.82387, saving model to ../checkpoints/pretrain-improvement-39-0.82.hdf5\n",
      "Epoch 40/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3242 - acc: 0.8893 - val_loss: 0.4935 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.82387\n",
      "Epoch 41/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3206 - acc: 0.8877 - val_loss: 0.4995 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.82387 to 0.82516, saving model to ../checkpoints/pretrain-improvement-41-0.83.hdf5\n",
      "Epoch 42/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3126 - acc: 0.8910 - val_loss: 0.5756 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.82516\n",
      "Epoch 43/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.3043 - acc: 0.8953 - val_loss: 0.5065 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.82516\n",
      "Epoch 44/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.2999 - acc: 0.8978 - val_loss: 0.5021 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.82516\n",
      "Epoch 45/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2969 - acc: 0.8981 - val_loss: 0.4824 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.82516 to 0.83032, saving model to ../checkpoints/pretrain-improvement-45-0.83.hdf5\n",
      "Epoch 46/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2927 - acc: 0.9000 - val_loss: 0.4858 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83032\n",
      "Epoch 47/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2890 - acc: 0.9002 - val_loss: 0.4841 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.83032\n",
      "Epoch 48/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.2814 - acc: 0.9040 - val_loss: 0.4693 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.83032 to 0.83484, saving model to ../checkpoints/pretrain-improvement-48-0.83.hdf5\n",
      "Epoch 49/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.2757 - acc: 0.9073 - val_loss: 0.4656 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.83484 to 0.84065, saving model to ../checkpoints/pretrain-improvement-49-0.84.hdf5\n",
      "Epoch 50/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2728 - acc: 0.9045 - val_loss: 0.4693 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.84065\n",
      "Epoch 51/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2675 - acc: 0.9088 - val_loss: 0.4964 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.84065\n",
      "Epoch 52/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2620 - acc: 0.9114 - val_loss: 0.4752 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.84065\n",
      "Epoch 53/160\n",
      "12400/12400 [==============================] - 131s 11ms/step - loss: 0.2635 - acc: 0.9098 - val_loss: 0.5105 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.84065\n",
      "Epoch 54/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2565 - acc: 0.9125 - val_loss: 0.4678 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.84065\n",
      "Epoch 55/160\n",
      "12400/12400 [==============================] - 135s 11ms/step - loss: 0.2522 - acc: 0.9130 - val_loss: 0.4627 - val_acc: 0.8406\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.84065\n",
      "Epoch 56/160\n",
      "12400/12400 [==============================] - 135s 11ms/step - loss: 0.2484 - acc: 0.9166 - val_loss: 0.4618 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.84065 to 0.84161, saving model to ../checkpoints/pretrain-improvement-56-0.84.hdf5\n",
      "Epoch 57/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.2455 - acc: 0.9188 - val_loss: 0.4632 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.84161 to 0.84161, saving model to ../checkpoints/pretrain-improvement-57-0.84.hdf5\n",
      "Epoch 58/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.2388 - acc: 0.9188 - val_loss: 0.4517 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.84161 to 0.84387, saving model to ../checkpoints/pretrain-improvement-58-0.84.hdf5\n",
      "Epoch 59/160\n",
      "12400/12400 [==============================] - 132s 11ms/step - loss: 0.2407 - acc: 0.9197 - val_loss: 0.4535 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.84387 to 0.84484, saving model to ../checkpoints/pretrain-improvement-59-0.84.hdf5\n",
      "Epoch 60/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2359 - acc: 0.9190 - val_loss: 0.4518 - val_acc: 0.8465\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.84484 to 0.84645, saving model to ../checkpoints/pretrain-improvement-60-0.85.hdf5\n",
      "Epoch 61/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2358 - acc: 0.9202 - val_loss: 0.4599 - val_acc: 0.8387\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.84645\n",
      "Epoch 62/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2279 - acc: 0.9223 - val_loss: 0.4511 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.84645 to 0.84742, saving model to ../checkpoints/pretrain-improvement-62-0.85.hdf5\n",
      "Epoch 63/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2283 - acc: 0.9233 - val_loss: 0.4696 - val_acc: 0.8426\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.84742\n",
      "Epoch 64/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2235 - acc: 0.9244 - val_loss: 0.4587 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.84742\n",
      "Epoch 65/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2216 - acc: 0.9252 - val_loss: 0.4539 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.84742\n",
      "Epoch 66/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2232 - acc: 0.9230 - val_loss: 0.4621 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84742\n",
      "Epoch 67/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2167 - acc: 0.9274 - val_loss: 0.4592 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.84742\n",
      "Epoch 68/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2114 - acc: 0.9311 - val_loss: 0.4439 - val_acc: 0.8468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: val_acc did not improve from 0.84742\n",
      "Epoch 69/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2108 - acc: 0.9288 - val_loss: 0.4546 - val_acc: 0.8423\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.84742\n",
      "Epoch 70/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2107 - acc: 0.9289 - val_loss: 0.4402 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.84742 to 0.85000, saving model to ../checkpoints/pretrain-improvement-70-0.85.hdf5\n",
      "Epoch 71/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.2045 - acc: 0.9321 - val_loss: 0.4481 - val_acc: 0.8432\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85000\n",
      "Epoch 72/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.2055 - acc: 0.9307 - val_loss: 0.4432 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85000\n",
      "Epoch 73/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.2013 - acc: 0.9345 - val_loss: 0.4461 - val_acc: 0.8503\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.85000 to 0.85032, saving model to ../checkpoints/pretrain-improvement-73-0.85.hdf5\n",
      "Epoch 74/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1995 - acc: 0.9333 - val_loss: 0.4406 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85032\n",
      "Epoch 75/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1974 - acc: 0.9345 - val_loss: 0.4569 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85032\n",
      "Epoch 76/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1943 - acc: 0.9340 - val_loss: 0.4454 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.85032 to 0.85419, saving model to ../checkpoints/pretrain-improvement-76-0.85.hdf5\n",
      "Epoch 77/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1945 - acc: 0.9335 - val_loss: 0.4488 - val_acc: 0.8506\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85419\n",
      "Epoch 78/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1915 - acc: 0.9360 - val_loss: 0.4494 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.85419\n",
      "Epoch 79/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1895 - acc: 0.9380 - val_loss: 0.4492 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85419\n",
      "Epoch 80/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1880 - acc: 0.9379 - val_loss: 0.4455 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.85419\n",
      "Epoch 81/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1861 - acc: 0.9385 - val_loss: 0.4508 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.85419\n",
      "Epoch 82/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1848 - acc: 0.9381 - val_loss: 0.4397 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.85419\n",
      "Epoch 83/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1828 - acc: 0.9392 - val_loss: 0.4349 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.85419 to 0.85484, saving model to ../checkpoints/pretrain-improvement-83-0.85.hdf5\n",
      "Epoch 84/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1834 - acc: 0.9402 - val_loss: 0.4472 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.85484\n",
      "Epoch 85/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1771 - acc: 0.9420 - val_loss: 0.4369 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.85484\n",
      "Epoch 86/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1796 - acc: 0.9410 - val_loss: 0.4433 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.85484\n",
      "Epoch 87/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1754 - acc: 0.9422 - val_loss: 0.4383 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.85484\n",
      "Epoch 88/160\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.1743 - acc: 0.9437 - val_loss: 0.4354 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.85484 to 0.85548, saving model to ../checkpoints/pretrain-improvement-88-0.86.hdf5\n",
      "Epoch 89/160\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.1721 - acc: 0.9439 - val_loss: 0.4319 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.85548 to 0.85613, saving model to ../checkpoints/pretrain-improvement-89-0.86.hdf5\n",
      "Epoch 90/160\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.1710 - acc: 0.9438 - val_loss: 0.4380 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.85613\n",
      "Epoch 91/160\n",
      "12400/12400 [==============================] - 122s 10ms/step - loss: 0.1686 - acc: 0.9443 - val_loss: 0.4519 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.85613\n",
      "Epoch 92/160\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.1689 - acc: 0.9443 - val_loss: 0.4432 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.85613\n",
      "Epoch 93/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1683 - acc: 0.9433 - val_loss: 0.4356 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.85613\n",
      "Epoch 94/160\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.1651 - acc: 0.9460 - val_loss: 0.4334 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.85613 to 0.85839, saving model to ../checkpoints/pretrain-improvement-94-0.86.hdf5\n",
      "Epoch 95/160\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.1638 - acc: 0.9467 - val_loss: 0.4601 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.85839\n",
      "Epoch 96/160\n",
      "12400/12400 [==============================] - 90s 7ms/step - loss: 0.1651 - acc: 0.9453 - val_loss: 0.4389 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.85839\n",
      "Epoch 97/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.1627 - acc: 0.9480 - val_loss: 0.4351 - val_acc: 0.8516\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.85839\n",
      "Epoch 98/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.1606 - acc: 0.9480 - val_loss: 0.4413 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.85839\n",
      "Epoch 99/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.1588 - acc: 0.9488 - val_loss: 0.4318 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.85839\n",
      "Epoch 100/160\n",
      "12400/12400 [==============================] - 134s 11ms/step - loss: 0.1568 - acc: 0.9501 - val_loss: 0.4434 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.85839\n",
      "Epoch 101/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.1548 - acc: 0.9510 - val_loss: 0.4330 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.85839\n",
      "Epoch 102/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.1560 - acc: 0.9524 - val_loss: 0.4406 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.85839\n",
      "Epoch 103/160\n",
      "12400/12400 [==============================] - 133s 11ms/step - loss: 0.1543 - acc: 0.9498 - val_loss: 0.4401 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.85839 to 0.86290, saving model to ../checkpoints/pretrain-improvement-103-0.86.hdf5\n",
      "Epoch 104/160\n",
      "12400/12400 [==============================] - 102s 8ms/step - loss: 0.1525 - acc: 0.9498 - val_loss: 0.4368 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.86290\n",
      "Epoch 105/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1533 - acc: 0.9505 - val_loss: 0.4386 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.86290\n",
      "Epoch 106/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1496 - acc: 0.9515 - val_loss: 0.4371 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.86290\n",
      "Epoch 107/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1501 - acc: 0.9514 - val_loss: 0.4436 - val_acc: 0.8552\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.86290\n",
      "Epoch 108/160\n",
      "12400/12400 [==============================] - 121s 10ms/step - loss: 0.1508 - acc: 0.9506 - val_loss: 0.4350 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.86290\n",
      "Epoch 109/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1468 - acc: 0.9549 - val_loss: 0.4383 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.86290\n",
      "Epoch 110/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1470 - acc: 0.9544 - val_loss: 0.4353 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.86290\n",
      "Epoch 111/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1453 - acc: 0.9540 - val_loss: 0.4367 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.86290\n",
      "Epoch 112/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1432 - acc: 0.9547 - val_loss: 0.4413 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.86290\n",
      "Epoch 113/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1438 - acc: 0.9549 - val_loss: 0.4360 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.86290\n",
      "Epoch 114/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1411 - acc: 0.9565 - val_loss: 0.4379 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.86290\n",
      "Epoch 115/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1424 - acc: 0.9533 - val_loss: 0.4389 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.86290\n",
      "Epoch 116/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1391 - acc: 0.9563 - val_loss: 0.4347 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.86290\n",
      "Epoch 117/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1394 - acc: 0.9544 - val_loss: 0.4515 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.86290\n",
      "Epoch 118/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1379 - acc: 0.9558 - val_loss: 0.4385 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.86290\n",
      "Epoch 119/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1391 - acc: 0.9562 - val_loss: 0.4421 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.86290\n",
      "Epoch 120/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1392 - acc: 0.9552 - val_loss: 0.4400 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.86290\n",
      "Epoch 121/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1353 - acc: 0.9573 - val_loss: 0.4365 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.86290\n",
      "Epoch 122/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1335 - acc: 0.9580 - val_loss: 0.4375 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.86290\n",
      "Epoch 123/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1359 - acc: 0.9573 - val_loss: 0.4451 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.86290\n",
      "Epoch 124/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1319 - acc: 0.9573 - val_loss: 0.4378 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.86290\n",
      "Epoch 125/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1311 - acc: 0.9591 - val_loss: 0.4357 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.86290\n",
      "Epoch 126/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1337 - acc: 0.9575 - val_loss: 0.4388 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.86290\n",
      "Epoch 127/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1315 - acc: 0.9573 - val_loss: 0.4429 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.86290\n",
      "Epoch 128/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1304 - acc: 0.9587 - val_loss: 0.4471 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.86290\n",
      "Epoch 129/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1303 - acc: 0.9594 - val_loss: 0.4414 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.86290\n",
      "Epoch 130/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1285 - acc: 0.9605 - val_loss: 0.4327 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.86290\n",
      "Epoch 131/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1269 - acc: 0.9603 - val_loss: 0.4420 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.86290\n",
      "Epoch 132/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1275 - acc: 0.9604 - val_loss: 0.4473 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.86290\n",
      "Epoch 133/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1261 - acc: 0.9608 - val_loss: 0.4543 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.86290\n",
      "Epoch 134/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1255 - acc: 0.9602 - val_loss: 0.4379 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.86290\n",
      "Epoch 135/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1247 - acc: 0.9606 - val_loss: 0.4386 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.86290\n",
      "Epoch 136/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1231 - acc: 0.9623 - val_loss: 0.4366 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.86290\n",
      "Epoch 137/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1235 - acc: 0.9610 - val_loss: 0.4369 - val_acc: 0.8597\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.86290\n",
      "Epoch 138/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1228 - acc: 0.9621 - val_loss: 0.4440 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.86290\n",
      "Epoch 139/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1222 - acc: 0.9618 - val_loss: 0.4366 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.86290 to 0.86387, saving model to ../checkpoints/pretrain-improvement-139-0.86.hdf5\n",
      "Epoch 140/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1210 - acc: 0.9623 - val_loss: 0.4352 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.86387 to 0.86452, saving model to ../checkpoints/pretrain-improvement-140-0.86.hdf5\n",
      "Epoch 141/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1199 - acc: 0.9631 - val_loss: 0.4418 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.86452\n",
      "Epoch 142/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1212 - acc: 0.9609 - val_loss: 0.4402 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.86452\n",
      "Epoch 143/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1201 - acc: 0.9626 - val_loss: 0.4381 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.86452\n",
      "Epoch 144/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1182 - acc: 0.9640 - val_loss: 0.4346 - val_acc: 0.8642\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.86452\n",
      "Epoch 145/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1167 - acc: 0.9640 - val_loss: 0.4350 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.86452\n",
      "Epoch 146/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1179 - acc: 0.9647 - val_loss: 0.4349 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.86452 to 0.86516, saving model to ../checkpoints/pretrain-improvement-146-0.87.hdf5\n",
      "Epoch 147/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1160 - acc: 0.9639 - val_loss: 0.4412 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.86516\n",
      "Epoch 148/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1161 - acc: 0.9637 - val_loss: 0.4412 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.86516\n",
      "Epoch 149/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1154 - acc: 0.9637 - val_loss: 0.4423 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.86516\n",
      "Epoch 150/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1144 - acc: 0.9642 - val_loss: 0.4472 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.86516\n",
      "Epoch 151/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1141 - acc: 0.9648 - val_loss: 0.4548 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.86516\n",
      "Epoch 152/160\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.1133 - acc: 0.9656 - val_loss: 0.4465 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.86516\n",
      "Epoch 153/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1147 - acc: 0.9640 - val_loss: 0.4483 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.86516\n",
      "Epoch 154/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1129 - acc: 0.9654 - val_loss: 0.4553 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.86516\n",
      "Epoch 155/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1129 - acc: 0.9653 - val_loss: 0.4677 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.86516\n",
      "Epoch 156/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1108 - acc: 0.9662 - val_loss: 0.4458 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.86516\n",
      "Epoch 157/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1099 - acc: 0.9666 - val_loss: 0.4339 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.86516 to 0.86548, saving model to ../checkpoints/pretrain-improvement-157-0.87.hdf5\n",
      "Epoch 158/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1099 - acc: 0.9665 - val_loss: 0.4414 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.86548\n",
      "Epoch 159/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1102 - acc: 0.9665 - val_loss: 0.4402 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.86548\n",
      "Epoch 160/160\n",
      "12400/12400 [==============================] - 71s 6ms/step - loss: 0.1110 - acc: 0.9664 - val_loss: 0.4455 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.86548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ea8fe8e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ts, y, epochs=160, batch_size=60, shuffle = True, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.43003543e-18 1.58722663e-20 1.92197895e-05 2.08068234e-17\n",
      "  8.03848063e-23 3.65828092e-23 7.28129462e-25 2.89224186e-21\n",
      "  2.36685523e-28 1.25216749e-24 0.00000000e+00 9.82686572e-27\n",
      "  1.91473382e-11 4.52976534e-15 5.58007852e-18 0.00000000e+00\n",
      "  4.61099325e-14 0.00000000e+00 4.56914367e-11 1.49332196e-34\n",
      "  0.00000000e+00 4.48089741e-33 0.00000000e+00 0.00000000e+00\n",
      "  1.33210655e-17 0.00000000e+00 1.27234792e-23 3.70998831e-36\n",
      "  7.34399607e-12 7.07296009e-32 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.22337058e-34 0.00000000e+00 3.43376631e-03\n",
      "  4.14116874e-13 0.00000000e+00 6.10624170e-07 0.00000000e+00\n",
      "  1.76821992e-15 0.00000000e+00 2.05466317e-23 0.00000000e+00\n",
      "  2.69745622e-24 8.96074536e-28 0.00000000e+00 3.35529479e-18\n",
      "  0.00000000e+00 0.00000000e+00 3.42411836e-13 3.49078006e-32\n",
      "  0.00000000e+00 4.30961737e-32 4.61232430e-09 4.55472425e-19\n",
      "  8.41349687e-38 0.00000000e+00 0.00000000e+00 9.30140762e-34\n",
      "  0.00000000e+00 9.96546447e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.predict(ts[:1,:,:,:]))\n",
    "y[0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wdi19",
   "language": "python",
   "name": "wdi19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
