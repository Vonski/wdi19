{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trening modelu pochodzącego od yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytaj dane treningowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      file          cx   cy      width  height classes\n",
      "39995       39995  9998.png  105.064378  3.5  20.600858      53       b\n",
      "39996       39996  9999.png    3.000000 -2.5  30.000000      65       q\n",
      "39997       39997  9999.png   27.000000  3.5  30.000000      53       f\n",
      "39998       39998  9999.png   52.000000  7.5  25.000000      45       5\n",
      "39999       39999  9999.png   99.000000  7.5  25.000000      45       s\n"
     ]
    }
   ],
   "source": [
    "train_set_labels = pd.read_csv(\"../data/yolo_train/labels.csv\")\n",
    "#test_set_labels = pd.read_csv(\"../data/yolo_test/labels.csv\")\n",
    "\n",
    "train_set_labels = train_set_labels.iloc[:40000]\n",
    "\n",
    "print(train_set_labels.tail())\n",
    "#test_set_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cx</th>\n",
       "      <th>cy</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000.00000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19999.50000</td>\n",
       "      <td>60.929345</td>\n",
       "      <td>3.065012</td>\n",
       "      <td>26.230247</td>\n",
       "      <td>53.869975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11547.14972</td>\n",
       "      <td>37.371776</td>\n",
       "      <td>3.621453</td>\n",
       "      <td>4.317903</td>\n",
       "      <td>7.242905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-6.500000</td>\n",
       "      <td>15.444015</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9999.75000</td>\n",
       "      <td>27.317073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.121387</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19999.50000</td>\n",
       "      <td>60.224719</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>25.411765</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29999.25000</td>\n",
       "      <td>94.065934</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39999.00000</td>\n",
       "      <td>139.230769</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0            cx            cy         width        height\n",
       "count  40000.00000  40000.000000  40000.000000  40000.000000  40000.000000\n",
       "mean   19999.50000     60.929345      3.065012     26.230247     53.869975\n",
       "std    11547.14972     37.371776      3.621453      4.317903      7.242905\n",
       "min        0.00000      2.000000     -6.500000     15.444015     45.000000\n",
       "25%     9999.75000     27.317073      0.000000     23.121387     45.000000\n",
       "50%    19999.50000     60.224719      3.500000     25.411765     53.000000\n",
       "75%    29999.25000     94.065934      7.500000     30.000000     60.000000\n",
       "max    39999.00000    139.230769      7.500000     35.000000     73.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = []\n",
    "    num = 0\n",
    "    for i in range(10000):\n",
    "        image = load_img(path + str(i) + \".png\")\n",
    "        arr = img_to_array(image)\n",
    "        data.append(arr)\n",
    "    return np.true_divide(np.array(data), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 60, 160, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = load_data(\"../data/yolo_train/\")\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Określenie szerkości siatki, rozmiaru batcha, liczby klas i wag poszczególnych części funkcji strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "HEIGHT = 60\n",
    "WIDTH = 160\n",
    "GRID_H = 8\n",
    "GRID_W = 8\n",
    "\n",
    "BATCH = 8\n",
    "CLASS_NUM = 62\n",
    "INPUT_SHAPE = train_set[1,:,:,:].shape\n",
    "\n",
    "COORD_SCALE, PROB_SCALE, OBJ_SCALE, NOOB_SCALE = 5.0, 1.0, 5.0, 0.1\n",
    "print(INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definicja modelu, na którym były trenowane wagi części konwolucyjnej (klasyfikacja liczb i liter)\n",
    "Jest nam to potrzebne, żeby móc wczytać wagi wyuczone na zbiorze pojedynczych znaków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leet/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1\n",
    "model.add(Conv2D(16, (3,3), strides=(1,1), padding='same', use_bias=False, input_shape=INPUT_SHAPE))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2\n",
    "model.add(Conv2D(32, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "# 4\n",
    "model.add(Conv2D(128, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same'))\n",
    "\n",
    "# 5\n",
    "model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# 6\n",
    "model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# 7\n",
    "model.add(Conv2D(CLASS_NUM, (8, 8), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "#model.add(Reshape((CLASS_NUM,)))\n",
    "\n",
    "# 7\n",
    "#model.add(Conv2D(4 + 1 + CLASS_NUM, (1, 1), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "#model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wczytanie wag modelu i modyfikacja sieci\n",
    "\n",
    "- Warstwy wcześniej przeuczone zostają wyłączone z dalszego treningu\n",
    "- Dwie ostatnia warstwa zostaje zastąpiona przez trzy nowe nie przeuczone warstwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../pretrain.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_layer = model.layers[-3].output\n",
    "top_model = Conv2D(512, (3,3), strides=(1,1), padding='same', use_bias=False)(connecting_layer)\n",
    "top_model = LeakyReLU(alpha=0.1)(top_model)\n",
    "top_model = Conv2D(512, (3,3), strides=(1,1), padding='same', use_bias=False)(top_model)\n",
    "top_model = LeakyReLU(alpha=0.1)(top_model)\n",
    "top_model = Conv2D(512, (1,1), strides=(1,1), padding='same')(top_model)\n",
    "top_model = LeakyReLU(alpha=0.1)(top_model)\n",
    "top_model = Conv2D(512, (1,1), strides=(1,1), padding='same')(top_model)\n",
    "top_model = LeakyReLU(alpha=0.1)(top_model)\n",
    "top_model = Conv2D(4 + 1 + CLASS_NUM, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(top_model)\n",
    "top_model = Activation('linear')(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 60, 160, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 160, 16)       432       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 60, 160, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 80, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 80, 32)        4608      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 40, 64)        18432     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 15, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 20, 128)        73728     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 20, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 20, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 20, 256)        294912    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 20, 256)        589824    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 20, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 20, 512)        1179648   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8, 20, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 20, 512)        2359296   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8, 20, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 20, 512)        262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 8, 20, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 20, 512)        262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 20, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 20, 67)         34371     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 20, 67)         0         \n",
      "=================================================================\n",
      "Total params: 5,080,563\n",
      "Trainable params: 4,098,627\n",
      "Non-trainable params: 981,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = Model(model.input, top_model)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmiana formatu zbioru etykiet\n",
    "Chcemy, żeby był taki sam jak wyjście z sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>cx</th>\n",
       "      <th>cy</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>39995</td>\n",
       "      <td>9998.png</td>\n",
       "      <td>105.064378</td>\n",
       "      <td>3.5</td>\n",
       "      <td>20.600858</td>\n",
       "      <td>53</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>39996</td>\n",
       "      <td>9999.png</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>39997</td>\n",
       "      <td>9999.png</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>39998</td>\n",
       "      <td>9999.png</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>39999</td>\n",
       "      <td>9999.png</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      file          cx   cy      width  height classes\n",
       "39995       39995  9998.png  105.064378  3.5  20.600858      53       b\n",
       "39996       39996  9999.png    3.000000 -2.5  30.000000      65       q\n",
       "39997       39997  9999.png   27.000000  3.5  30.000000      53       f\n",
       "39998       39998  9999.png   52.000000  7.5  25.000000      45       5\n",
       "39999       39999  9999.png   99.000000  7.5  25.000000      45       s"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_labels.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          3.5        56.08247423 53.         24.74226804  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>cy</th>\n",
       "      <th>cx</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.041237</td>\n",
       "      <td>60</td>\n",
       "      <td>28.041237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>56.082474</td>\n",
       "      <td>53</td>\n",
       "      <td>24.742268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>86.597938</td>\n",
       "      <td>45</td>\n",
       "      <td>20.618557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>115.463918</td>\n",
       "      <td>45</td>\n",
       "      <td>20.618557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.855422</td>\n",
       "      <td>61</td>\n",
       "      <td>32.771084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence   cy          cx  height      width  0  1  2  3  4  ...  q  r  \\\n",
       "0           1  0.0   28.041237      60  28.041237  0  0  0  0  0  ...  0  0   \n",
       "1           1  3.5   56.082474      53  24.742268  0  0  0  0  0  ...  0  0   \n",
       "2           1  7.5   86.597938      45  20.618557  0  0  0  0  0  ...  0  0   \n",
       "3           1  7.5  115.463918      45  20.618557  0  0  0  0  0  ...  0  0   \n",
       "4           1 -0.5    3.855422      61  32.771084  0  0  0  0  0  ...  0  0   \n",
       "\n",
       "   s  t  u  v  w  x  y  z  \n",
       "0  0  0  0  0  0  0  0  0  \n",
       "1  0  0  0  0  0  0  0  0  \n",
       "2  0  0  0  0  0  0  0  0  \n",
       "3  0  0  0  0  0  0  0  1  \n",
       "4  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = train_set_labels.loc[:, [\"cx\", \"cy\", \"width\", \"height\"]]\n",
    "tmp = pd.get_dummies(train_set_labels.loc[:, \"classes\"])\n",
    "gt[\"confidence\"]=1\n",
    "gt = gt.loc[:, [\"confidence\", \"cy\", \"cx\", \"height\", \"width\"]]\n",
    "gt2 = gt.merge(tmp, left_index=True, right_index=True)\n",
    "print(gt2.head().values[1,:])\n",
    "gt2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.75      , 0.25773196, 7.5       , 3.50515464,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.75      , 0.55670103, 6.625     , 3.09278351,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.75      , 0.11340206, 5.625     , 2.57731959,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.75      , 0.72164948, 5.625     , 2.57731959,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = gt2.values\n",
    "cy = d[:,1] + np.true_divide(d[:,3],2)\n",
    "cx = d[:,2] + np.true_divide(d[:,4],2)\n",
    "bynum = np.floor(np.divide(cy,GRID_H))\n",
    "bxnum = np.floor(np.divide(cx,GRID_W))\n",
    "by = np.true_divide(cy-np.multiply(bynum, GRID_H), GRID_H)\n",
    "bx = np.true_divide(cx-np.multiply(bxnum, GRID_W), GRID_W)\n",
    "bh = np.true_divide(d[:,3],GRID_H)\n",
    "bw = np.true_divide(d[:,4],GRID_W)\n",
    "bynum = bynum.astype(int)\n",
    "bxnum = bxnum.astype(int)\n",
    "\n",
    "d[:,1] = by\n",
    "d[:,2] = bx\n",
    "d[:,3] = bh\n",
    "d[:,4] = bw\n",
    "\n",
    "tsgt = np.zeros((10000, 8, 20, 67)) # zamien na numclass\n",
    "for i in range(10000):\n",
    "    for j in range(4):\n",
    "        tsgt[i,bynum[i+j],bxnum[i+j],:] = d[i+j,:]\n",
    "tsgt[0,3,:,0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definicja funkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(real_y, pred_y):\n",
    "    pred_box_conf = tf.expand_dims(tf.sigmoid(pred_y[:,:,:,0]), -1)\n",
    "    \n",
    "    pred_box_xy = tf.sigmoid(pred_y[:,:,:,1:3])\n",
    "    real_box_xy = real_y[:,:,:,1:3]\n",
    "    \n",
    "    pred_box_wh = tf.exp(pred_y[:,:,:,3:5])\n",
    "    real_box_wh = real_y[:,:,:,3:5]\n",
    "    \n",
    "    pred_class_prob = tf.nn.softmax(pred_y[:,:,:,5:])\n",
    "    real_class_prob = real_y[:,:,:,5:]\n",
    "    \n",
    "    pred_y = tf.concat([pred_box_conf, pred_box_xy, pred_box_wh, pred_class_prob], 3)\n",
    "    \n",
    "    pred_box_ul = pred_box_xy - 0.5 * pred_box_wh\n",
    "    pred_box_br = pred_box_xy + 0.5 * pred_box_wh\n",
    "    pred_box_area = pred_box_wh[:,:,:,0] * pred_box_wh[:,:,:,1]\n",
    "    pred_box_wh = tf.sqrt(pred_box_wh)\n",
    "    \n",
    "    real_box_ul = real_box_xy - 0.5 * real_box_wh\n",
    "    real_box_br = real_box_xy + 0.5 * real_box_wh\n",
    "    real_box_area = real_box_wh[:,:,:,0] * real_box_wh[:,:,:,1]\n",
    "    real_box_wh = tf.sqrt(real_box_wh)\n",
    "    \n",
    "    intersect_ul = tf.maximum(pred_box_ul, real_box_ul) \n",
    "    intersect_br = tf.minimum(pred_box_br, real_box_br)\n",
    "    intersect_wh = intersect_br - intersect_ul\n",
    "    intersect_wh = tf.maximum(intersect_wh, 0.0)\n",
    "    intersect_area = intersect_wh[:,:,:,0] * intersect_wh[:,:,:,1]\n",
    "    \n",
    "    iou = tf.truediv(intersect_area, pred_box_area + real_box_area - intersect_area)\n",
    "    real_box_conf = tf.expand_dims(iou * real_y[:,:,:,0], -1)\n",
    "    \n",
    "    coord_w = tf.concat(4 * [tf.expand_dims(real_y[:,:,:,0],-1)], 3)\n",
    "    coord_w = COORD_SCALE * coord_w\n",
    "    \n",
    "    conf_w = NOOB_SCALE * (1. - tf.expand_dims(real_y[:,:,:,0],-1)) + OBJ_SCALE * tf.expand_dims(real_y[:,:,:,0],-1)\n",
    "    \n",
    "    prob_w = tf.concat(CLASS_NUM * [tf.expand_dims(real_y[:,:,:,0],-1)], 3) \n",
    "    prob_w = PROB_SCALE * prob_w \n",
    "    \n",
    "    real_y = tf.concat([real_box_conf, real_box_xy, real_box_wh, real_class_prob], 3)\n",
    "    weights = tf.concat([conf_w, coord_w, prob_w], 3)\n",
    "    \n",
    "    loss = tf.pow(pred_y - real_y, 2)\n",
    "    loss = loss * weights\n",
    "    loss = tf.reshape(loss, [-1, int(GRID_W*GRID_H*(4 + 1 + CLASS_NUM)*2.5)])\n",
    "    loss = tf.reduce_sum(loss, 1)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    #print(loss.eval(session=tf.Session()))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W tej komórce testowałem funkcję błędu (debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.     0.375  0.9375 1.75   6.625  0.     1.    ]\n",
      "[ 4.6  -0.5   2.71  0.56  1.89  0.    1.  ]\n"
     ]
    }
   ],
   "source": [
    "real = np.zeros((2, 8, 20, 7))\n",
    "real[0, 1, 3, :] = [1, 0.375, 0.9375, 1.75, 6.625, 0, 1]\n",
    "real[1, 1, 3, :] = [1, 0.375, 0.9375, 1.75, 6.625, 1, 0]\n",
    "pred = np.zeros((2, 8, 20, 7))\n",
    "pred[0, 1, 3, :] = [4.6, -0.5, 2.71, 0.56, 1.89, 0, 1]\n",
    "pred[1, 1, 3, :] = [4.6, -0.5, 2.71, 0.56, 1.89, 1, 0]\n",
    "print(tf.convert_to_tensor(real).eval(session=tf.Session())[0,1,3,:])\n",
    "print(tf.convert_to_tensor(pred).eval(session=tf.Session())[0,1,3,:])\n",
    "#my_loss(tf.convert_to_tensor(real), tf.convert_to_tensor(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wybór optymalizatora, ustawień uczenia i sposobu zapisywania wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.load_weights('../mean_yolo.14.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.000001, decay=0.0005, momentum=0.9)\n",
    "adam = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00005)\n",
    "new_model.compile(loss=my_loss, optimizer=adam)\n",
    "\n",
    "filepath=\"../checkpoints/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leet/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "9000/9000 [==============================] - 632s 70ms/step - loss: 7.1924 - val_loss: 4.2463\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.24630, saving model to ../checkpoints/weights-improvement-01-4.25.hdf5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = '../checkpoints/weights-improvement-01-4.25.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-82ed78330dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Golem/wdi19/.venv/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '../checkpoints/weights-improvement-01-4.25.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "new_model.fit(train_set, tsgt, epochs=1, batch_size=2, shuffle = True, validation_split=0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sprawdzenie wyników predykcji na pierwszym przykładzie ze zbioru treningowego\n",
    "Pozwala to ocenić wyłącznie jak dobrze model przystosował się do tego konkretnego zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = new_model.predict(train_set[:1,:,:,:])\n",
    "print(np.amax(tsgt[:,:,:,0]))\n",
    "print(sigmoid(np.amax(p[:,:,:,0])))\n",
    "print(\"confidence:\")\n",
    "print(tsgt[0,3,[5,8,12,15],0])\n",
    "print(sigmoid(p[:,3,[5,8,12,15],0]))\n",
    "print(\"cy:\")\n",
    "print(tsgt[0,3,[5,8,12,15],1])\n",
    "print(sigmoid(p[:,3,[5,8,12,15],1]))\n",
    "print(\"cx:\")\n",
    "print(tsgt[0,3,[5,8,12,15],2])\n",
    "print(sigmoid(p[:,3,[5,8,12,15],2]))\n",
    "print(\"height:\")\n",
    "print(tsgt[0,3,[5,8,12,15],3])\n",
    "print(np.exp(p[:,3,[5,8,12,15],3]))\n",
    "print(\"width:\")\n",
    "print(tsgt[0,3,[5,8,12,15],4])\n",
    "print(np.exp(p[:,3,[5,8,12,15],4]))\n",
    "print(\"probs:\")\n",
    "print(tsgt[0,3,[5,8,12,15],5:])\n",
    "print((p[:,3,[5,8,12,15],5:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wdi19",
   "language": "python",
   "name": "wdi19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
